{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import datasets, metrics\n",
    "import math\n",
    "training1 = pd.read_csv('https://raw.githubusercontent.com/EmZhu/HiggsBoson/master/train_jet0_final.csv')\n",
    "training2 = pd.read_csv('https://raw.githubusercontent.com/EmZhu/HiggsBoson/master/train_jet1_final.csv')\n",
    "training3 = pd.read_csv('https://raw.githubusercontent.com/EmZhu/HiggsBoson/master/train_jet2.3_final.csv')\n",
    "sub_training1=training1.drop('EventId',1).drop('Label',1).drop('Weight',1)\n",
    "sub_training2=training2.drop('EventId',1).drop('Label',1).drop('Weight',1)\n",
    "sub_training3=training3.drop('EventId',1).drop('Label',1).drop('Weight',1)\n",
    "training_set=[sub_training1,sub_training2,sub_training3]\n",
    "training1.ix[training1.Label=='s','Label']=0\n",
    "training1.ix[training1.Label=='b','Label']=1\n",
    "training2.ix[training2.Label=='s','Label']=0\n",
    "training2.ix[training2.Label=='b','Label']=1\n",
    "training3.ix[training3.Label=='s','Label']=0\n",
    "training3.ix[training3.Label=='b','Label']=1\n",
    "for i in range(len(training_set)):\n",
    "    length=len(training_set[i])\n",
    "    subset_length=length/10\n",
    "    exec(\"training_val\"+str(i) + \" = []\")\n",
    "    for j in range(9):\n",
    "        temp_set=training_set[i][(subset_length*j):(subset_length*(j+1))]\n",
    "        exec(\"training_val\"+str(i) + \".append(temp_set)\")\n",
    "    temp_set=training_set[i][(subset_length*9):]\n",
    "    exec(\"training_val\"+str(i) + \".append(temp_set)\")\n",
    "sub_test1=training1['Label']\n",
    "sub_test2=training2['Label']\n",
    "sub_test3=training3['Label']\n",
    "testing_set=[sub_test1,sub_test2,sub_test3]\n",
    "for i in range(len(testing_set)):\n",
    "    length=len(testing_set[i])\n",
    "    subset_length=length/10\n",
    "    exec(\"test_val\"+str(i) + \" = []\")\n",
    "    for j in range(9):\n",
    "        temp_set=testing_set[i][(subset_length*j):(subset_length*(j+1))]\n",
    "        exec(\"test_val\"+str(i) + \".append(temp_set)\")\n",
    "    temp_set=testing_set[i][(subset_length*9):]\n",
    "    exec(\"test_val\"+str(i) + \".append(temp_set)\")\n",
    "sub_weight1=training1['Weight']\n",
    "sub_weight2=training2['Weight']\n",
    "sub_weight3=training3['Weight']\n",
    "weight_set=[sub_weight1,sub_weight2,sub_weight3]\n",
    "for i in range(len(weight_set)):\n",
    "    length=len(weight_set[i])\n",
    "    subset_length=length/10\n",
    "    exec(\"weight_val\"+str(i) + \" = []\")\n",
    "    for j in range(9):\n",
    "        temp_set=weight_set[i][(subset_length*j):(subset_length*(j+1))]\n",
    "        exec(\"weight_val\"+str(i) + \".append(temp_set)\")\n",
    "    temp_set=weight_set[i][(subset_length*9):]\n",
    "    exec(\"weight_val\"+str(i) + \".append(temp_set)\")\n",
    "eval_x=[training_val0,training_val1,training_val2]\n",
    "eval_y=[test_val0,test_val1,test_val2]\n",
    "eval_w=[weight_val0,weight_val1,weight_val2]\n",
    "def AMS(real,pred,weight):\n",
    "    pred_s_ind=np.array(pred==0)\n",
    "    real_s_ind=np.array(real==0)\n",
    "    real_b_ind=np.array(real==1)\n",
    "    \n",
    "    s=np.sum(weight[pred_s_ind & real_s_ind])\n",
    "    b=np.sum(weight[pred_s_ind & real_b_ind])\n",
    "    \n",
    "    b_tau=10\n",
    "    ans=math.sqrt(2*((s+b+b_tau)*math.log(1+s/(b+b_tau))-s))\n",
    "    return (ans)\n",
    "sumarray=np.load('sumarray.npy')\n",
    "\n",
    "mean_array=np.apply_along_axis(lambda x: np.mean(x), 1, sumarray)\n",
    "mean_array1=mean_array[range(11)]\n",
    "mean_array2=mean_array[range(11,22)]\n",
    "mean_array3=mean_array[range(22,33)]\n",
    "\n",
    "units_for_1=np.argmax(mean_array1)+10\n",
    "units_for_2=np.argmax(mean_array2)+10\n",
    "units_for_3=np.argmax(mean_array3)+10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: `feature_columns` will be required after 2016-08-01.\n",
      "Instructions for updating:\n",
      "Pass `tf.contrib.learn.infer_real_valued_columns_from_input(x)` or `tf.contrib.learn.infer_real_valued_columns_from_input_fn(input_fn)` as `feature_columns`, where `x` or `input_fn` is your argument to `fit`, `evaluate`, or `predict`.\n",
      "WARNING:tensorflow:Change warning: `feature_columns` will be required after 2016-08-01.\n",
      "Instructions for updating:\n",
      "Pass `tf.contrib.learn.infer_real_valued_columns_from_input(x)` or `tf.contrib.learn.infer_real_valued_columns_from_input_fn(input_fn)` as `feature_columns`, where `x` or `input_fn` is your argument to `fit`, `evaluate`, or `predict`.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/12/67skz20j57z6372h421h6qwc0000gn/T/tmpAsJG2t\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/12/67skz20j57z6372h421h6qwc0000gn/T/tmpAsJG2t\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(18)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(18)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 'GradientDescentOptimizer', '0.001')\n",
      "0.334027217212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: `feature_columns` will be required after 2016-08-01.\n",
      "Instructions for updating:\n",
      "Pass `tf.contrib.learn.infer_real_valued_columns_from_input(x)` or `tf.contrib.learn.infer_real_valued_columns_from_input_fn(input_fn)` as `feature_columns`, where `x` or `input_fn` is your argument to `fit`, `evaluate`, or `predict`.\n",
      "WARNING:tensorflow:Change warning: `feature_columns` will be required after 2016-08-01.\n",
      "Instructions for updating:\n",
      "Pass `tf.contrib.learn.infer_real_valued_columns_from_input(x)` or `tf.contrib.learn.infer_real_valued_columns_from_input_fn(input_fn)` as `feature_columns`, where `x` or `input_fn` is your argument to `fit`, `evaluate`, or `predict`.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/12/67skz20j57z6372h421h6qwc0000gn/T/tmpBbF1il\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/12/67skz20j57z6372h421h6qwc0000gn/T/tmpBbF1il\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(18)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(18)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 1, 'GradientDescentOptimizer', '0.001')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-34b53325bfef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mtrain_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meval_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mtrain_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meval_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0;31m#temp_units2.append(classifier)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/dato-env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    238\u001b[0m                              \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                              \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                              max_steps=max_steps)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/dato-env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps)\u001b[0m\n\u001b[1;32m    576\u001b[0m           \u001b[0mfail_on_nan_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfail_on_nan_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m           \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m           max_steps=max_steps)\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extract_metric_update_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/dato-env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.pyc\u001b[0m in \u001b[0;36m_supervised_train\u001b[0;34m(graph, output_dir, train_op, loss_op, global_step_tensor, init_op, init_feed_dict, init_fn, log_every_steps, supervisor_is_chief, supervisor_master, supervisor_save_model_secs, keep_checkpoint_max, supervisor_save_summaries_steps, feed_fn, steps, fail_on_nan_loss, monitors, max_steps)\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuper_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         _, loss = super_sess.run([train_op, loss_op], feed_fn() if feed_fn else\n\u001b[0m\u001b[1;32m    280\u001b[0m                                  None)\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/dato-env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.pyc\u001b[0m in \u001b[0;36m_feed_dict_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# self.n_classes is None means we're passing in raw target indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m           \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer=['GradientDescentOptimizer','AdadeltaOptimizer','AdagradOptimizer','AdamOptimizer','FtrlOptimizer','RMSPropOptimizer']\n",
    "max_mean=[units_for_1,units_for_2,units_for_3]\n",
    "learning_rate=['0.001','0.002','0.003','0.004','0.005','0.006','0.007','0.008','0.009','0.01']\n",
    "\n",
    "learning_model=[]\n",
    "for learn in learning_rate:\n",
    "    num_of_units=[]\n",
    "    for k in range(len(eval_x)):\n",
    "        #set_group2=[]\n",
    "        i=max_mean[k]\n",
    "        temp_units=[]\n",
    "        #temp_units2=[]\n",
    "        for l in optimizer:\n",
    "            optimizer_group=[]\n",
    "            for j in range(10):\n",
    "                print (k,j,l,learn)\n",
    "                exec('classifier=tf.contrib.learn.DNNClassifier(hidden_units=[i], n_classes=2,optimizer=tf.train.'+l+'(learning_rate='+learn+'))')\n",
    "                validation_x=eval_x[k][j]\n",
    "                validation_y=eval_y[k][j]\n",
    "                validation_w=eval_w[k][j]\n",
    "                train_x=pd.concat(eval_x[k][:j]+eval_x[k][j+1:])\n",
    "                train_y=pd.concat(eval_y[k][:j]+eval_y[k][j+1:])\n",
    "                classifier.fit(x=train_x.values, y=np.array(train_y, dtype=np.int), steps=200)\n",
    "                #temp_units2.append(classifier)\n",
    "                pred=classifier.predict(validation_x.values)\n",
    "                accuracy=AMS(validation_y.values,pred,validation_w.values)\n",
    "                print (accuracy)\n",
    "                optimizer_group.append(accuracy)\n",
    "            temp_units.append(optimizer_group)\n",
    "        num_of_units.append(temp_units)\n",
    "    learning_model.append(num_of_units)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
